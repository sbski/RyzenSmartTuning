
<cpu_events>

<!--
       Family 15h Microarchitecture performance monitor events (Preliminary)

       Source: BIOS and Kernel Developer's Guide for the AMD Family 15h
       Models 00h-0Fh Processors, Rev 1.23, September 20, 2011 (Preliminary)

       Event source to performance counter assignment table


           Unit  PERF_CTL  Mask

           ====  ========  ====

            FP    [5:3]    0x38

            LS    [5:0]    0x3F

            DC    [5:0]    0x3F

            CU    [2:0]    0x07

            IC    [2:0]    0x07

            EX    [5:0]    0x3F

            DE    [2:0]    0x07

            NB    [3:0]    0x0F


       Events that do not fit these general assignment rules are:


           Event 0x08F. Implemented by IC. PERF_CTL[0].



       There are no events in the range 0x0A0:0x0BF (BKDG section 3.17.6).


       Copyright (c) 2011 Advanced Micro Devices, Inc.


       Date: September 22, 2011

-->

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; FP
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="FP" counters="38">

<event name="FPU Pipe Assignment" abbreviation="FPU ops" value="0" counters="8" >
	<mask value="0" name="Total number uops assigned to Pipe 0" />
	<mask value="1" name="Total number uops assigned to Pipe 1" />
	<mask value="2" name="Total number uops assigned to Pipe 2" />
	<mask value="3" name="Total number uops assigned to Pipe 3" />
	<mask value="4" name="Total number dual-pipe uops assigned to Pipe 0" />
	<mask value="5" name="Total number dual-pipe uops assigned to Pipe 1" />
	<mask value="6" name="Total number dual-pipe uops assigned to Pipe 2" />
	<mask value="7" name="Total number dual-pipe uops assigned to Pipe 3" />
	<op_name name="op" value="DISPATCHED_FPU_OPS" />
	<description>The number of operations (uops) and dual-pipe uops dispatched to each of the 4 FPU execution pipelines. This event reflects how busy the FPU pipelines are and may be used for workload characterization. This includes all operations performed by x87, MMX, and SSE instructions, including moves. Each increment represents a one-cycle dispatch event. This event is a speculative event. Since this event includes non-numeric operations it is not suitable for measuring MFLOPS.</description>
</event>

<event name="FP Scheduler Empty" abbreviation="Cycles FPU emtpy" value="1" >
	<op_name name="op" value="CYCLES_FPU_EMPTY" />
	<description>This is a speculative event. The number of cycles in which the FPU scheduler is empty. Note that some ops like FP loads bypass the scheduler; see the FP MAS for the full list of "no pipe" ops that bypass the scheduler.</description>
</event>

<event name="Retired Floating Point Ops" abbreviation="Retired FP Ops" value="3" counters="8" >
	<mask value="0" name="Single-precision add/subtract FLOPS" />
	<mask value="1" name="Single-precision multiply FLOPS" />
	<mask value="2" name="Single-precision divide/square root FLOPS" />
	<mask value="3" name="Single precision multiply-add FLOPS. Multiply-add counts as 2 FLOPS" />
	<mask value="4" name="Double precision add/subtract FLOPS" />
	<mask value="5" name="Double precision multiply FLOPS" />
	<mask value="6" name="Double precision divide/square root FLOPS" />
	<mask value="7" name="Double precision multiply-add FLOPS. Multiply-add counts as 2 FLOPS" />
	<op_name name="op" value="RETIRED_SSE_OPS" />
	<description>This is a retire-based event. The number of retired FLOPS. The number of events logged per cycle can vary from 0 to 32.</description>
</event>

<event name="Number of Move Elimination and Scalar Op Optimization" abbreviation="Move scalar opt" value="4" counters="8" >
	<mask value="0" name="Number of SSE Move Ops" />
	<mask value="1" name="Number of SSE Move Ops eliminated" />
	<mask value="2" name="Number of Ops that are candidates for optimization (Z-bit set or pass)" />
	<mask value="3" name="Number of Scalar ops optimized" />
	<op_name name="op" value="MOVE_SCALAR_OPTIMIZATION" />
	<description>This is a dispatch based speculative event, and is useful for measuring the effectiveness of the Move elimination and Scalar code optimization schemes.</description>
</event>

<event name="Retired Serializing Ops" abbreviation="Ret serializing ops" value="5" >
	<mask value="0" name="SSE bottom-executing uops retired" />
	<mask value="1" name="SSE control word mispredict traps due to mispredictions" />
	<mask value="2" name="x87 bottom-executing uops retired" />
	<mask value="3" name="x87 control word mispredict traps due to mispredictions" />
	<op_name name="op" value="RETIRED_SERIALIZING_OPS" />
	<description>The number of serializing ops retired.</description>
</event>

<event name="Number of Cycles that a Bottom-Execute uop is in the FP Scheduler" abbreviation="Bottom exec op" value="6" >
	<op_name name="op" value="BOTTOM_EXECUTE_OP" />
	<description>This is a speculative event.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; LS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="LS" counters="3F">

<event name="Segment Register Loads" abbreviation="Seg reg loads" value="20" >
	<mask value="0" name="ES" />
	<mask value="1" name="CS" />
	<mask value="2" name="SS" />
	<mask value="3" name="DS" />
	<mask value="4" name="FS" />
	<mask value="5" name="GS" />
	<mask value="6" name="HS" />
	<op_name name="op" value="SEGMENT_REGISTER_LOADS" />
	<description>The number of segment register loads performed.</description>
</event>

<event name="Pipeline Restart Due to Self-Modifying Code" abbreviation="Restart self-mod code" value="21" >
	<op_name name="op" value="PIPELINE_RESTART_DUE_TO_SELF_MODIFYING_CODE" />
	<description>The number of pipeline restarts that were caused by self-modifying code (a store that hits any instruction that's been fetched for execution beyond the instruction doing the store).</description>
</event>

<event name="Pipeline Restart Due to Probe Hit" abbreviation="Restart probe hit" value="22" >
	<op_name name="op" value="PIPELINE_RESTART_DUE_TO_PROBE_HIT" />
	<description>The number of pipeline restarts caused by an invalidating probe hitting on a speculative out-of-order load.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; DE
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="DE" counters="7">

<event name="Load Queue/Store Queue Full" abbreviation="LD/ST queue full" value="23" >
	<mask value="0" name="The number of cycles that the load buffer is full" />
	<mask value="1" name="The number of cycles that the store buffer is full" />
	<op_name name="op" value="LOAD_Q_STORE_Q_FULL" />
	<description>The number of cycles that the load queue (LDQ) or store queue (STQ) is full. The load queue holds loads that missed the data cache and are waiting on a refill; the store queue holds stores waiting to retire. This condition stalls further data cache accesses, although such stalls may be overlapped by independent instruction execution.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; LS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="LS" counters="3F">

<event name="Locked Operations" abbreviation="Locked ops" value="24" >
	<mask value="0" name="Number of locked instructions executed" />
	<mask value="2" name="Number of cycles spent non-speculative phase (including cache miss penalty)" />
	<mask value="3" name="Number of cycles waiting for a cache hit (cache miss penalty)" />
	<op_name name="op" value="LOCKED_OPS" />
	<description>This event covers locked operations performed and their non-speculative execution time.</description>
</event>

<event name="Retired CLFLUSH Instructions" abbreviation="Ret CLFLUSH inst" value="26" >
	<op_name name="op" value="RETIRED_CLFLUSH_INSTRUCTIONS" />
	<description>The number of retired CLFLUSH instructions. This is a non-speculative event.</description>
</event>

<event name="Retired CPUID Instructions" abbreviation="Ret CPUID inst" value="27" >
	<op_name name="op" value="RETIRED_CPUID_INSTRUCTIONS" />
	<description>The number of CPUID instructions retired.</description>
</event>

<event name="LS Dispatch" abbreviation="LS dispatch" value="29" >
	<mask value="0" name="Loads" />
	<mask value="1" name="Stores" />
	<mask value="2" name="Load-op-Stores" />
	<op_name name="op" value="LS_DISPATCH" />
	<description>Counts the number of operations dispatched to the LS unit.</description>
</event>

<event name="Canceled Store to Load Forward Operations" abbreviation="Cancelled fwd ops" value="2a" >
	<mask value="0" name="Store is smaller than load or different starting byte but partial overlap" />
	<op_name name="op" value="CANCELLED_STORE_TO_LOAD" />
	<description>Counts the number of canceled store to load forward operations.</description>
</event>

<event name="SMIs Received" abbreviation="SMIs received" value="2b" >
	<op_name name="op" value="SMIS_RECEIVED" />
	<description>Counts the number of SMIs received.</description>
</event>

<event name="Executed CLFLUSH Instructions" abbreviation="Exec CFLUSH inst" value="30" >
	<op_name name="op" value="EXECUTED_CFLUSH_INST" />
	<description>The number of executed CLFLUSH instructions. This is a speculative event.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; DC
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="DC" counters="3F">

<event name="Data Cache Accesses" abbreviation="DC accesses" value="40" >
	<op_name name="op" value="DATA_CACHE_ACCESSES" />
	<description>The number of accesses to the data cache for load and store references. This may include certain microcode scratchpad accesses, although these are generally rare. This event is a speculative event.</description>
</event>

<event name="Data Cache Misses" abbreviation="DC misses" value="41" >
	<mask value="0" name="First data cache miss or streaming store to a 64B cache line" />
	<mask value="1" name="First streaming store to a 64B cache line" />
	<op_name name="op" value="DATA_CACHE_MISSES" />
	<description>The number of data cache references which missed in the data cache. This event is a speculative event. Only the first miss for a given line is included; access attempts by other instructions while the refill is still pending are not included in this event. Each event reflects one 64 B cache line refill, and counts of this event are the same as, or very close to, the combined count for PMCx042.</description>
</event>

<event name="Data Cache Refills from L2 or System" abbreviation="DC refills L2/SYS" value="42" >
	<mask value="0" name="Fill with good data. (Final valid status is valid)" />
	<mask value="1" name="Early valid status turned out to be invalid" />
	<mask value="3" name="Fill with read data error" />
	<op_name name="op" value="DATA_CACHE_REFILLS_FROM_L2_OR_NORTHBRIDGE" />
	<description>The number of data cache refills satisfied from the L2 cache and/or the system. Each increment reflects a 64 B transfer. This event is a speculative event.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; CU
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="CU" counters="7">

<event name="Data Cache Refills from System" abbreviation="DC refills SYS" value="43" >
	<op_name name="op" value="DATA_CACHE_REFILLS_FROM_NORTHBRIDGE" />
	<description>The number of L1 cache refills satisfied from the system (system memory or another cache), as opposed to the L2. Each increment reflects a 64 B transfer. This event is a speculative event.</description>
</event>

<event name="Unified TLB Hit" abbreviation="TLB hit" value="45" >
	<mask value="0" name="4 KB unified TLB hit for data" />
	<mask value="1" name="2 MB unified TLB hit for data" />
	<mask value="2" name="1 GB unified TLB hit for data" />
	<mask value="4" name="4 KB unified TLB hit for instruction" />
	<mask value="5" name="2 MB unified TLB hit for instruction" />
	<mask value="6" name="1 GB unified TLB hit for instruction" />
	<op_name name="op" value="UNIFIED_TLB_HIT" />
	<description>The number of TLB accesses that miss in the L1 DTLB or L1 and L2 ITLBs and hit in the unified TLB (UCTLB). This event is a speculative event.</description>
</event>

<event name="Unified TLB Miss" abbreviation="TLB miss" value="46" >
	<mask value="0" name="4 KB unified TLB miss for data" />
	<mask value="1" name="2 MB unified TLB miss for data" />
	<mask value="2" name="1 GB unified TLB miss for data" />
	<mask value="4" name="4 KB unified TLB miss for instruction" />
	<mask value="5" name="2 MB unified TLB miss for instruction" />
	<mask value="6" name="1 GB unified TLB miss for instruction" />
	<op_name name="op" value="UNIFIED_TLB_MISS" />
	<description>The number of TLB accesses that miss in all TLBs. This event is a speculative event.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; DC
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="DC" counters="3F">

<event name="Misaligned Accesses" abbreviation="Misalign access" value="47" >
	<op_name name="op" value="MISALIGNED_ACCESSES" />
	<description>The number of data cache accesses that are misaligned. These are accesses which cross an 8 B boundary. They incur an extra cache access (reflected in PMCx040), and an extra cycle of latency on reads. This event is a speculative event.</description>
</event>

<event name="Prefetch Instructions Dispatched" abbreviation="Prefetch inst" value="4b" >
	<mask value="0" name="Load (Prefetch, PrefetchT0/T1/T2)" />
	<mask value="1" name="Store (PrefetchW)" />
	<mask value="2" name="NTA (PrefetchNTA)" />
	<op_name name="op" value="PREFETCH_INSTRUCTIONS_DISPATCHED" />
	<description>The number of prefetch instructions dispatched by the decoder. Such instructions may or may not cause a cache line transfer. Any Dcache and L2 accesses, hits and misses by prefetch instructions are included in these types of events. This event is a speculative event.</description>
</event>

<event name="Ineffective Software Prefetches" abbreviation="Ineffective SW prefetch" value="52" >
	<mask value="0" name="Software prefetch hit in the L1" />
	<mask value="3" name="Software prefetch hit in the L2" />
	<op_name name="op" value="INEFFECTIVE_SW_PREFETCHES" />
	<description>The number of software prefetches that did not fetch data outside of the processor core.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; CU
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="CU" counters="7">

<event name="Memory Requests by Type" abbreviation="Memory req" value="65" >
	<mask value="0" name="Requests to non-cacheable (UC) memory" />
	<mask value="1" name="Requests to non-cacheable (WC, but not WC+/SS) memory" />
	<mask value="7" name="Requests to non-cacheable (WC+/SS, but not WC) memory" />
	<op_name name="op" value="MEMORY_REQUESTS" />
	<description>These events reflect accesses to uncacheable (UC), write-combining (WC), and streaming store (SS) activity to WB memory.</description>
</event>

<event name="Data Prefetcher" abbreviation="Data prefetcher" value="67" >
	<mask value="1" name="Prefetch attempts" />
	<op_name name="op" value="DATA_PREFETCHER" />
	<description>Prefetch attempts.</description>
</event>

<event name="MAB Requests" abbreviation="MAB req" value="68" >
	<mask value="0" name="Buffer entry index bit 0" />
	<mask value="1" name="Buffer entry index bit 1" />
	<mask value="2" name="Buffer entry index bit 2" />
	<mask value="3" name="Buffer entry index bit 3" />
	<mask value="4" name="Buffer entry index bit 4" />
	<mask value="5" name="Buffer entry index bit 5" />
	<mask value="6" name="Buffer entry index bit 6" />
	<mask value="7" name="Buffer entry index bit 7" />
	<op_name name="op" value="MAB_REQS" />
	<description>Events PMCx068 and PMCx069 reflect utilization of the Miss Address buffers (MABs), which handle IC, DC, TLB, WCC, and WCB related requests. The UnitMask[BufferID] is an encoded value which selects one of the MABs. PMCx068 counts the number of cacheable L2 misses handled by the selected MAB; PMCx069 counts the number of cycles the selected MAB is busy waiting for the NB response. The average latency seen by the selected MAB is the number of cycles spent waiting (PMCx069) divided by the number of requests (PMCx068).</description>
</event>

<event name="MAB Wait Cycles" abbreviation="MAB wait" value="69" >
	<mask value="0" name="Buffer entry index bit 0" />
	<mask value="1" name="Buffer entry index bit 1" />
	<mask value="2" name="Buffer entry index bit 2" />
	<mask value="3" name="Buffer entry index bit 3" />
	<mask value="4" name="Buffer entry index bit 4" />
	<mask value="5" name="Buffer entry index bit 5" />
	<mask value="6" name="Buffer entry index bit 6" />
	<mask value="7" name="Buffer entry index bit 7" />
	<op_name name="op" value="MAB_WAIT" />
	<description>Events PMCx068 and PMCx069 reflect utilization of the Miss Address buffers (MABs), which handle IC, DC, TLB, WCC, and WCB related requests. The UnitMask[BufferID] is an encoded value which selects one of the MABs. PMCx068 counts the number of cacheable L2 misses handled by the selected MAB; PMCx069 counts the number of cycles the selected MAB is busy waiting for the NB response. The average latency seen by the selected MAB is the number of cycles spent waiting (PMCx069) divided by the number of requests (PMCx068).</description>
</event>

<event name="Response From System on Cache Refills" abbreviation="SYS read resp" value="6c" >
	<mask value="0" name="Exclusive" />
	<mask value="1" name="Modified (D18F0x68[ATMModeEn]==0), Modified written (D18F0x68[ATMModeEn]==1)" />
	<mask value="2" name="Shared" />
	<mask value="3" name="Owned" />
	<mask value="4" name="Data Error" />
	<mask value="5" name="Modified unwritten" />
	<op_name name="op" value="SYSTEM_READ_RESPONSES" />
	<description>The number of responses from the system for cache refill requests. The UnitMask may be used to select specific cache coherency states. Each increment represents one 64 B cache line transferred from the system (DRAM or another cache, including another core on the same node) to the data cache, instruction cache or L2 cache (for data prefetcher and TLB table walks). Modified-state responses may be for Dcache store miss refills, PrefetchW software prefetches, hardware prefetches for a store-miss stream, or Change-to-Dirty requests that get a dirty (Owned) probe hit in another cache. Exclusive responses may be for any Icache refill, Dcache load miss refill, other software prefetches, hardware prefetches for a load-miss stream, or TLB table walks that miss in the L2 cache; Shared responses may be for any of those that hit a clean line in another cache.</description>
</event>

<event name="Octwords Written to System" abbreviation="Oct written to SYS" value="6d" >
	<mask value="0" name="OW write transfer" />
	<op_name name="op" value="OCTWORD_WRITE_TRANSFERS" />
	<description>The number of OW (16 B) data transfers from the processor to the system. These may be part of a 64 B cache line writeback or a 64 B dirty probe hit response, each of which would cause four increments; or a partial or complete Write Combining buffer flush (Sized Write), which could cause from one to four increments.</description>
</event>

<event name="Cache Cross-invalidates" abbreviation="Cross-invalidates" value="75" >
	<mask value="0" name="DC Invalidates IC" />
	<mask value="1" name="DC Invalidates DC" />
	<mask value="2" name="IC Invalidates IC" />
	<mask value="3" name="IC Invalidates DC" />
	<op_name name="op" value="CACHE_CROSS_INVALIDATES" />
	<description>These reflect internal probes for Icache or Dcache misses that hit in the Dcache or Icache, causing the line to be invalidated. These may result from code modification, or data being located too close to code, or virtual address aliasing. The aliasing cases arise when a physical memory location is referenced via two or more virtual addresses which differ in bits 14:12.</description>
</event>

<event name="CPU Clocks not Halted" abbreviation="CPU clocks" value="76" >
	<op_name name="op" value="CPU_CLK_UNHALTED" />
	<description>The number of core clocks that the CPU is not in a halted state (due to STPCLK or a HLT instruction). This event allows system idle time to be automatically factored out from IPC (or CPI) measurements, providing the OS halts the CPU when going idle. If the OS goes into an idle loop rather than halting, such calculations are influenced by the IPC of the idle loop. The core clock frequency varies with P-states.</description>
</event>

<event name="Requests to L2 Cache" abbreviation="L2 requests" value="7d" >
	<mask value="0" name="IC fill" />
	<mask value="1" name="DC fill" />
	<mask value="2" name="TLB fill (page table walks)" />
	<mask value="3" name="NB probe request" />
	<mask value="4" name="Canceled request" />
	<mask value="6" name="L2 cache prefetcher request" />
	<op_name name="op" value="REQUESTS_TO_L2" />
	<description>The number of requests to the L2 cache for Icache or Dcache fills, or page table lookups for the TLB. These events reflect only read requests to the L2; writes to the L2 are indicated by PMCx07E. See PMCx081, PMCx082, PMCx083, PMCx041, PMCx042, PMCx043.</description>
</event>

<event name="L2 Cache Misses" abbreviation="L2 misses" value="7e" >
	<mask value="0" name="IC fill" />
	<mask value="1" name="DC fill (includes possible replays, whereas PMCx041 does not)" />
	<mask value="2" name="TLB page table walk" />
	<mask value="4" name="L2 Cache Prefetcher request" />
	<op_name name="op" value="L2_CACHE_MISS" />
	<description>The number of requests that miss in the L2 cache. This may include some amount of speculative activity. The IC-fill-miss and DC-fill-miss events tend to mirror the Icache and Dcache refill-from-system PMCx083 and PMCx043, and tend to include more speculative activity than those events.</description>
</event>

<event name="L2 Fill/Writeback" abbreviation="L2 fill/writeback" value="7f" >
	<mask value="0" name="L2 fills from system" />
	<mask value="1" name="L2 Writebacks to system (Clean and Dirty)" />
	<mask value="2" name="L2 Clean Writebacks to system" />
	<op_name name="op" value="L2_CACHE_FILL_WRITEBACK" />
	<description>Each increment represents a 64 B cache line transfer.</description>
</event>

<event name="Page Splintering" abbreviation="Page splinter" value="165" >
	<mask value="0" name="Guest page size is larger than host page size when nested paging is enabled" />
	<mask value="1" name="Splintering due to MTRRs, IORRs, APIC, TOMs or other special address region" />
	<mask value="2" name="Host page size is larger than the guest page size" />
	<op_name name="op" value="PAGE_SPLINTERING" />
	<description>Counts the number of TLB reloads where a large page is installed into the TLB as a smaller page size.</description>
</event>

<event name="L2 Prefetcher Trigger Events" abbreviation="L2 prefetch trigger" value="16c" >
	<mask value="0" name="Load L1 miss seen by prefetcher" />
	<mask value="1" name="Store L1 miss seen by prefetcher" />
	<op_name name="op" value="L2_PREFETCHER_TRIGGER" />
	<description>Prefetcher miss.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; IC
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="IC" counters="7">

<event name="Instruction Cache Fetches" abbreviation="IC fetches" value="80" >
	<op_name name="op" value="INSTRUCTION_CACHE_FETCHES" />
	<description>The number of instruction cache accesses by the instruction fetcher. Each access is an aligned 32 B read, from which a varying number of instructions may be decoded.</description>
</event>

<event name="Instruction Cache Misses" abbreviation="IC misses" value="81" >
	<op_name name="op" value="INSTRUCTION_CACHE_MISSES" />
	<description>The number of instruction fetches and prefetch requests that miss in the instruction cache. This is typically equal to or very close to the sum of events 82h and 83h. Each miss results in a 64 B cache line refill.</description>
</event>

<event name="Instruction Cache Refills from L2" abbreviation="IC refills from L2" value="82" >
	<op_name name="op" value="INSTRUCTION_CACHE_REFILLS_FROM_L2" />
	<description>The number of instruction cache refills satisfied from the L2 cache. Each increment represents one 64 B cache line transfer.</description>
</event>

<event name="Instruction Cache Refills from System" abbreviation="IC refills from sys" value="83" >
	<op_name name="op" value="INSTRUCTION_CACHE_REFILLS_FROM_SYSTEM" />
	<description>The number of instruction cache refills from system memory (or another cache). Each increment represents one 64 B cache line transfer.</description>
</event>

<event name="L1 ITLB Miss, L2 ITLB Hit" abbreviation="ITLB L1M L2H" value="84" >
	<op_name name="op" value="L1_ITLB_MISS_AND_L2_ITLB_HIT" />
	<description>The number of instruction fetches that miss in the L1 ITLB but hit in the L2 TLB.</description>
</event>

<event name="L1 ITLB Miss, L2 ITLB Miss" abbreviation="ITLB L1M L2M" value="85" >
	<mask value="0" name="Instruction fetches to a 4 KB page" />
	<mask value="1" name="Instruction fetches to a 2 MB page" />
	<mask value="2" name="Instruction fetches to a 1 GB page" />
	<op_name name="op" value="L1_ITLB_MISS_AND_L2_ITLB_MISS" />
	<description>The number of instruction fetches that miss in both the L1 and L2 TLBs.</description>
</event>

<event name="Pipeline Restart Due to Instruction Stream Probe" abbreviation="Restart i-stream probe" value="86" >
	<op_name name="op" value="PIPELINE_RESTART_DUE_TO_INSTRUCTION_STREAM_PROBE" />
	<description>The number of pipeline restarts caused by invalidating probes that hit on the instruction stream currently being executed. This would happen if the active instruction stream was being modified by another processor in an MP system - typically a highly unlikely event.</description>
</event>

<event name="Instruction Fetch Stall" abbreviation="Inst fetch stall" value="87" >
	<op_name name="op" value="INSTRUCTION_FETCH_STALL" />
	<description>The number of cycles the instruction fetcher is stalled for the core. This may be for a variety of reasons such as branch predictor updates, unconditional branch bubbles, far jumps and cache misses, instruction fetching for the other core while instruction fetch for this core is stalled, among others. May be overlapped by instruction dispatch stalls or instruction execution, such that these stalls don't necessarily impact performance.</description>
</event>

<event name="Return Stack Hits" abbreviation="RET stack hits" value="88" >
	<op_name name="op" value="RETURN_STACK_HITS" />
	<description>The number of near return instructions (RET or RET Iw) that get their return address from the return address stack (i.e. where the stack has not gone empty) for the core. This may include cases where the address is incorrect (return mispredicts). This may also include speculatively executed false-path returns. Return mispredicts are typically caused by the return address stack underflowing, however they may also be caused by an imbalance in calls vs. returns, such as doing a call but then popping the return address off the stack. This event cannot be reliably compared with events C9h and CAh (such as to calculate percentage of return mispredicts due to an empty return address stack), since it may include speculatively executed false-path returns that are not included in those retire-time events.</description>
</event>

<event name="Return Stack Overflows" abbreviation="RET stack overflows" value="89" >
	<op_name name="op" value="RETURN_STACK_OVERFLOWS" />
	<description>The number of (near) call instructions that cause the return address stack to overflow. When this happens, the oldest entry is discarded. This count may include speculatively executed calls.</description>
</event>

<event name="Instruction Cache Victims" abbreviation="IC victims" value="8b" >
	<op_name name="op" value="INSTRUCTION_CACHE_VICTIMS" />
	<description>The number of cachelines evicted from the instruction cache to the L2. This event is not core specific and for either core counts the IC victims caused by both cores of the compute unit.</description>
</event>

<event name="Instruction Cache Lines Invalidated" abbreviation="IC lines invalid" value="8c" >
	<mask value="0" name="Non-SMC invalidating probe that missed on in-flight instructions" />
	<mask value="1" name="Non-SMC invalidating probe that hit on in-flight instructions" />
	<mask value="2" name="SMC invalidating probe that missed on in-flight instructions" />
	<mask value="3" name="SMC invalidating probe that hit on in-flight instructions" />
	<op_name name="op" value="INSTRUCTION_CACHE_INVALIDATED" />
	<description>The number of instruction cache lines invalidated. A non-SMC event is CMC (cross modifying code), either from the other core of the compute unit or another compute compute unit.</description>
</event>

<event name="ITLB Reloads" abbreviation="ITLB reloads" value="99" >
	<op_name name="op" value="ITLB_RELOADS" />
	<description>The number of ITLB reload requests.</description>
</event>

<event name="ITLB Reloads Aborted" abbreviation="ITLB reloads aborted" value="9a" >
	<op_name name="op" value="ITLB_RELOADS_ABORTED" />
	<description>The number of ITLB reloads aborted.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; EX
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="EX" counters="3F">

<event name="Retired Instructions" abbreviation="Ret inst" value="c0" >
	<op_name name="op" value="RETIRED_INSTRUCTIONS" />
	<description>The number of instructions retired (execution completed and architectural state updated). This count includes exceptions and interrupts - each exception or interrupt is counted as one  instruction.</description>
</event>

<event name="Retired uops" abbreviation="Ret uops" value="c1" >
	<op_name name="op" value="RETIRED_UOPS" />
	<description>The number of micro-ops retired. This includes all processor activity (instructions, exceptions, interrupts, microcode assists, etc.). The number of events logged per cycle can vary from 0 to 4.</description>
</event>

<event name="Retired Branch Instructions" abbreviation="Ret branch" value="c2" >
	<op_name name="op" value="RETIRED_BRANCH_INSTRUCTIONS" />
	<description>The number of branch instructions retired. This includes all types of architectural control flow changes, including exceptions and interrupts.</description>
</event>

<event name="Retired Mispredicted Branch Instructions" abbreviation="Ret misp branch" value="c3" >
	<op_name name="op" value="RETIRED_MISPREDICTED_BRANCH_INSTRUCTIONS" />
	<description>The number of branch instructions retired, of any type, that were not correctly predicted. This includes those for which prediction is not attempted (far control transfers, exceptions and interrupts).</description>
</event>

<event name="Retired Taken Branch Instructions" abbreviation="Ret taken branch" value="c4" >
	<op_name name="op" value="RETIRED_TAKEN_BRANCH_INSTRUCTIONS" />
	<description>The number of taken branches that were retired. This includes all types of architectural control flow changes, including exceptions and interrupts.</description>
</event>

<event name="Retired Taken Branch Instructions Mispredicted" abbreviation="Ret taken branch misp" value="c5" >
	<op_name name="op" value="RETIRED_TAKEN_BRANCH_INSTRUCTIONS_MISPREDICTED" />
	<description>The number of retired taken branch instructions that were mispredicted.</description>
</event>

<event name="Retired Far Control Transfers" abbreviation="Ret far xfers" value="c6" >
	<op_name name="op" value="RETIRED_FAR_CONTROL_TRANSFERS" />
	<description>The number of far control transfers retired including far call/jump/return, IRET, SYSCALL and SYSRET, plus exceptions and interrupts. Far control transfers are not subject to branch prediction.</description>
</event>

<event name="Retired Branch Resyncs" abbreviation="Ret branch resyncs" value="c7" >
	<op_name name="op" value="RETIRED_BRANCH_RESYNCS" />
	<description>The number of resync branches. These reflect pipeline restarts due to certain microcode assists and events such as writes to the active instruction stream, among other things. Each occurrence reflects a restart penalty similar to a branch mispredict. This is relatively rare.</description>
</event>

<event name="Retired Near Returns" abbreviation="Ret near RET" value="c8" >
	<op_name name="op" value="RETIRED_NEAR_RETURNS" />
	<description>The number of near return instructions (RET or RET Iw) retired.</description>
</event>

<event name="Retired Near Returns Mispredicted" abbreviation="Ret near RET misp" value="c9" >
	<op_name name="op" value="RETIRED_NEAR_RETURNS_MISPREDICTED" />
	<description>The number of near returns retired that were not correctly predicted by the return address predictor. Each such mispredict incurs the same penalty as a mispredicted conditional branch instruction.</description>
</event>

<event name="Retired Indirect Branches Mispredicted" abbreviation="Ret ind branch misp" value="ca" >
	<op_name name="op" value="RETIRED_INDIRECT_BRANCHES_MISPREDICTED" />
	<description>The number of indirect branch instructions retired where the target address was not correctly predicted.</description>
</event>

<event name="Retired MMX/FP Instructions" abbreviation="Ret MMX/FP inst" value="cb" >
	<mask value="0" name="x87 instructions" />
	<mask value="1" name="MMX(tm) instructions" />
	<mask value="2" name="SSE instructions (SSE,SSE2,SSE3,SSSE3,SSE4A,SSE4.1,SSE4.2,AVX,XOP,FMA4)" />
	<op_name name="op" value="RETIRED_MMX_FP_INSTRUCTIONS" />
	<description>The number of MMX, SSE or x87 instructions retired. The UnitMask allows the selection of the individual classes of instructions as given in the table. Each increment represents one complete instruction. Since this event includes non-numeric instructions it is not suitable for measuring MFLOPS.</description>
</event>

<event name="Interrupts-Masked Cycles" abbreviation="Int-masked cycles" value="cd" >
	<op_name name="op" value="INTERRUPTS_MASKED_CYCLES" />
	<description>The number of processor cycles where interrupts are masked (EFLAGS.IF = 0). Using edgecounting with this event gives the number of times IF is cleared; dividing the cycle-count value by this value gives the average length of time that interrupts are disabled on each instance. Compare the edge count with PMCx0CF to determine how often interrupts are disabled for interrupt handling vs. other reasons (e.g. critical sections).</description>
</event>

<event name="Interrupts-Masked Cycles with Interrupt Pending" abbreviation="Int-masked pending" value="ce" >
	<op_name name="op" value="INTERRUPTS_MASKED_CYCLES_WITH_INTERRUPT_PENDING" />
	<description>The number of processor cycles where interrupts are masked (EFLAGS.IF = 0) and an interrupt is pending. Using edge-counting with this event and comparing the resulting count with the edge count for PMCx0CD gives the proportion of interrupts for which handling is delayed due to prior interrupts being serviced, critical sections, etc. The cycle count value gives the total amount of time for such delays. The cycle count divided by the edge count gives the average length of each such delay.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; LS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="LS" counters="3F">

<event name="Interrupts Taken" abbreviation="Int taken" value="cf" >
	<op_name name="op" value="INTERRUPTS_TAKEN" />
	<description>The number of hardware interrupts taken. This does not include software interrupts (INT n instruction).</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; DE
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="DE" counters="7">

<event name="Decoder Empty" abbreviation="Decoder empty" value="d0" >
	<op_name name="op" value="DECODER_EMPTY" />
	<description>The number of processor cycles where the decoder has nothing to dispatch (typically waiting on an instruction fetch that missed the Icache, or for the target fetch after a branch mispredict).</description>
</event>

<event name="Dispatch Stalls" abbreviation="Dispatch stalls" value="d1" >
	<op_name name="op" value="DISPATCH_STALLS" />
	<description>The number of processor cycles where the decoder is stalled for any reason (has one or more instructions ready but can't dispatch them due to resource limitations in execution). This event requires that the other core of the compute unit is in the Halt state. This is the combined effect of events PMCx0D3 to PMCx0D9, some of which may overlap; this event reflects the net stall cycles. The more common stall conditions (events PMCx0D5, PMCx0D6, PMCx0D7, PMCx0D8) may overlap considerably. The occurrence of these stalls is highly dependent on the nature of the code being executed (instruction mix, memory reference patterns, etc.).</description>
</event>

<event name="Microsequencer Stall due to Serialization" abbreviation="Stall serialization" value="d3" >
	<op_name name="op" value="DISPATCH_STALL_FOR_SERIALIZATION" />
	<description>The number of processor cycles the microsequencer is stalled due to a serializing operation, which waits for the execution pipeline to drain. Relatively rare; mainly associated with system instructions. See PMCx0D1.</description>
</event>

<event name="Dispatch Stall for Instruction Retire Q Full" abbreviation="Stall retire queue" value="d5" >
	<op_name name="op" value="DISPATCH_STALL_FOR_RETIRE_QUEUE_FULL" />
	<description>The number of processor cycles the decoder is stalled because the instruction retire Q is full. This event requires that the other core of the compute unit is in the Halt state. May occur simultaneously with certain other stall conditions; see PMCx0D1.</description>
</event>

<event name="Dispatch Stall for Integer Scheduler Queue Full" abbreviation="Stall int sched" value="d6" >
	<op_name name="op" value="DISPATCH_STALL_FOR_INT_SCHED_QUEUE_FULL" />
	<description>The number of processor cycles the decoder is stalled because a required integer unit scheduler queue is full. This event requires that the other core of the compute unit is in the Halt state. May occur simultaneously with certain other stall conditions; see PMCx0D1.</description>
</event>

<event name="Dispatch Stall for FP Scheduler Queue Full" abbreviation="Stall FPU full" value="d7" >
	<op_name name="op" value="DISPATCH_STALL_FOR_FPU_FULL" />
	<description>The number of processor cycles the decoder is stalled because the scheduler for the Floating Point scheduler queue is full. This event requires that the other core of the compute unit is in the Halt state. This condition can be caused by a lack of parallelism in FP-intensive code, or by cache misses on FP operand loads (which could also show up as PMCx0D8 instead, depending on the nature of the instruction sequences). May occur simultaneously with certain other stall conditions; see PMCx0D1.</description>
</event>

<event name="Dispatch Stall for LDQ Full" abbreviation="Stall LDQ full" value="d8" >
	<op_name name="op" value="DISPATCH_STALL_FOR_LDQ_FULL" />
	<description>The number of processor cycles the decoder is stalled because the load queue is full. This event requires that the other core of the compute unit is in the Halt state. This generally occurs due to heavy cache miss activity. May occur simultaneously with certain other stall conditions; see PMCx0D1.</description>
</event>

<event name="Microsequencer Stall Waiting for All Quiet" abbreviation="Stall waiting quiet" value="d9" >
	<op_name name="op" value="MICROSEQ_STALL_WAITING_FOR_ALL_QUIET" />
	<description>The number of processor cycles the microsequencer is stalled waiting for all outstanding requests to the system to be resolved. Relatively rare; associated with certain system instructions and types of interrupts. May partially overlap certain other stall conditions; see PMCx0D1.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; EX
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="EX" counters="3F">

<event name="FPU Exceptions" abbreviation="FPU except" value="db" >
	<mask value="0" name="Total microfaults" />
	<mask value="1" name="Total microtraps" />
	<mask value="2" name="Int2Ext faults" />
	<mask value="3" name="Ext2Int faults" />
	<mask value="4" name="Bypass faults" />
	<op_name name="op" value="FPU_EXCEPTIONS" />
	<description>The number of floating point unit exceptions for microcode assists. The UnitMask may be used to isolate specific types of exceptions.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; LS
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="LS" counters="3F">

<event name="DR0 Breakpoint Match" abbreviation="DR0 matches" value="dc" >
	<op_name name="op" value="DR0_BREAKPOINTS" />
	<description>Register Mapping for PMCx0D[F:C] - Register=>Function: PMCx0DC=>DR0 PMCx0DD=>DR1 PMCx0DE=>DR2 PMCx0DF=>DR3. The number of matches on the address in breakpoint register DR[3:0], per the breakpoint type specified in DR7. Data matches: * Data matches are counted if the breakpoint is enabled and the data access becomes non-speculative, but not necessarily retired. * Load/store breakpoint matches do not incur any overhead. Instruction matches: * Instruction matches becomes non-speculative, but not necessarily retired. Instruction matches do not depend on the breakpoint being enabled. * Each instruction breakpoint match incurs an overhead of about 120 cycles</description>
</event>

<event name="DR1 Breakpoint Match" abbreviation="DR1 matches" value="dd" >
	<op_name name="op" value="DR1_BREAKPOINTS" />
	<description>Register Mapping for PMCx0D[F:C] - Register=>Function: PMCx0DC=>DR0 PMCx0DD=>DR1 PMCx0DE=>DR2 PMCx0DF=>DR3. The number of matches on the address in breakpoint register DR[3:0], per the breakpoint type specified in DR7. Data matches: * Data matches are counted if the breakpoint is enabled and the data access becomes non-speculative, but not necessarily retired. * Load/store breakpoint matches do not incur any overhead. Instruction matches: * Instruction matches becomes non-speculative, but not necessarily retired. Instruction matches do not depend on the breakpoint being enabled. * Each instruction breakpoint match incurs an overhead of about 120 cycles</description>
</event>

<event name="DR2 Breakpoint Match" abbreviation="DR2 matches" value="de" >
	<op_name name="op" value="DR2_BREAKPOINTS" />
	<description>Register Mapping for PMCx0D[F:C] - Register=>Function: PMCx0DC=>DR0 PMCx0DD=>DR1 PMCx0DE=>DR2 PMCx0DF=>DR3. The number of matches on the address in breakpoint register DR[3:0], per the breakpoint type specified in DR7. Data matches: * Data matches are counted if the breakpoint is enabled and the data access becomes non-speculative, but not necessarily retired. * Load/store breakpoint matches do not incur any overhead. Instruction matches: * Instruction matches becomes non-speculative, but not necessarily retired. Instruction matches do not depend on the breakpoint being enabled. * Each instruction breakpoint match incurs an overhead of about 120 cycles</description>
</event>

<event name="DR3 Breakpoint Match" abbreviation="DR3 matches" value="df" >
	<op_name name="op" value="DR3_BREAKPOINTS" />
	<description>Register Mapping for PMCx0D[F:C] - Register=>Function: PMCx0DC=>DR0 PMCx0DD=>DR1 PMCx0DE=>DR2 PMCx0DF=>DR3. The number of matches on the address in breakpoint register DR[3:0], per the breakpoint type specified in DR7. Data matches: * Data matches are counted if the breakpoint is enabled and the data access becomes non-speculative, but not necessarily retired. * Load/store breakpoint matches do not incur any overhead. Instruction matches: * Instruction matches becomes non-speculative, but not necessarily retired. Instruction matches do not depend on the breakpoint being enabled. * Each instruction breakpoint match incurs an overhead of about 120 cycles</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; EX
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="EX" counters="3F">

<event name="Tagged IBS Ops" abbreviation="IBS ops tagged" value="1cf" >
	<mask value="0" name="Number of ops tagged by IBS" />
	<mask value="1" name="Number of ops tagged by IBS that retired" />
	<mask value="2" name="Number of times op could not be tagged by IBS because of previous tagged op that has not retired" />
	<op_name name="op" value="IBS_OPS_TAGGED" />
	<description>Tagged IBS Ops.</description>
</event>

<event name="Dispatch Stall for STQ Full" abbreviation="Stall STQ full" value="1d8" >
	<op_name name="op" value="DISPATCH_STALL_FOR_STQ_FULL" />
	<description>The number of processor cycles the decoder is stalled because the store queue is full. This event requires that the other core of the compute unit is in the Halt state. This generally occurs due to heavy cache miss activity. May occur simultaneously with certain other stall conditions.</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; NB
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="NB" counters="F">

<event name="DRAM Accesses" abbreviation="DRAM accesses" value="e0" >
	<mask value="0" name="DCT0 Page hit" />
	<mask value="1" name="DCT0 Page Miss" />
	<mask value="2" name="DCT0 Page Conflict" />
	<mask value="3" name="DCT1 Page hit" />
	<mask value="4" name="DCT1 Page Miss" />
	<mask value="5" name="DCT1 Page Conflict" />
	<op_name name="op" value="DRAM_ACCESSES" />
	<description>The number of memory accesses performed by the local DRAM controller. UnitMask[7:0] may be used to isolate the different DRAM page access cases. Page miss cases incur an extra latency to open a page; page conflict cases incur both a page-close as well as page-open penalties. These penalties may be overlapped by DRAM accesses for other requests and don't necessarily represent lost DRAM bandwidth. The associated penalties are as follows: Page miss: Trcd (DRAM RAS-to-CAS delay). Page conflict: Trp + Trcd (DRAM row-precharge time plus RAS-to-CAS delay). Each DRAM access represents one 64-byte block of data transferred if the DRAM is configured for 64-byte granularity, or one 32-byte block if the DRAM is configured for 32-byte granularity. (The latter is only applicable to single-channel DRAM systems, which may be configured either way.)</description>
</event>

<event name="DRAM Controller Page Table Overflows" abbreviation="Page table overflows" value="e1" >
	<mask value="0" name="DCT0 Page Table Overflow" />
	<mask value="1" name="DCT1 Page Table Overflow" />
	<op_name name="op" value="MEMORY_CONTROLLER_PAGE_TABLE_OVERFLOWS" />
	<description>The number of page table overflows in the local DRAM controller. This table maintains information about which DRAM pages are open. An overflow occurs when a request for a new page arrives when the maximum number of pages are already open. Each occurrence reflects an access latency penalty equivalent to a page conflict.</description>
</event>

<event name="Memory Controller DRAM Command Slots Missed" abbreviation="DRAM cmd slot miss" value="e2" >
	<mask value="0" name="DCT0 Command Slots Missed (in MemClks)" />
	<mask value="1" name="DCT1 Command Slots Missed (in MemClks)" />
	<op_name name="op" value="MEMORY_CONTROLLER_SLOT_MISSED" />
	<description>Memory Controller DRAM Command Slots Missed.</description>
</event>

<event name="Memory Controller Turnarounds" abbreviation="Turnarounds" value="e3" >
	<mask value="0" name="DCT0 DIMM (chip select) turnaround" />
	<mask value="1" name="DCT0 Read to write turnaround" />
	<mask value="2" name="DCT0 Write to read turnaround" />
	<mask value="3" name="DCT1 DIMM (chip select) turnaround" />
	<mask value="4" name="DCT1 Read to write turnaround" />
	<mask value="5" name="DCT1 Write to read turnaround" />
	<op_name name="op" value="MEMORY_CONTROLLER_TURNAROUNDS" />
	<description>The number of turnarounds on the local DRAM data bus. UnitMask[7:0] may be used to isolate the different cases. These represent lost DRAM bandwidth, which may be calculated as follows (in bytes per occurrence): DIMM turnaround: DRAM_width_in_bytes * 2 edges_per_memclk * 2; R/W turnaround: DRAM_width_in_bytes * 2 edges_per_memclk * 1; R/W turnaround: DRAM_width_in_bytes * 2 edges_per_memclk * (Tcl-1); where DRAM_width_in_bytes is 8 or 16 (for single- or dual-channel systems), and Tcl is the CAS latency of the DRAM in memory system clock cycles (where the memory clock for DDR-400, or PC3200 DIMMS, for example, would be 200 MHz).</description>
</event>

<event name="Memory Controller Bypass Counter Saturation" abbreviation="Bypass ctr sat" value="e4" >
	<mask value="0" name="Memory controller high priority bypass" />
	<mask value="1" name="Memory controller medium priority bypass" />
	<mask value="2" name="DCT0 DCQ bypass" />
	<mask value="3" name="DCT1 DCQ bypass" />
	<op_name name="op" value="MEMORY_CONTROLLER_BYPASS_COUNTER_SATURATION" />
	<description>Memory Controller Bypass Counter Saturation.</description>
</event>

<event name="Thermal Status" abbreviation="Thermal status" value="e8" >
	<mask value="2" name="Number of times the HTC trip point is crossed" />
	<mask value="5" name="Number of clocks HTC P-state is inactive" />
	<mask value="6" name="Number of clocks HTC P-state is active" />
	<op_name name="op" value="THERMAL_STATUS" />
	<description>Thermal Status</description>
</event>

<event name="CPU/IO Requests to Memory/IO" abbreviation="CPU/IO req mem/IO" value="e9" >
	<mask value="0" name="IO to IO" />
	<mask value="1" name="IO to Mem" />
	<mask value="2" name="CPU to IO" />
	<mask value="3" name="CPU to Mem" />
	<mask value="4" name="To remote node" />
	<mask value="5" name="To local node" />
	<mask value="6" name="From remote node" />
	<mask value="7" name="From local node" />
	<op_name name="op" value="CPU_IO_REQUESTS_TO_MEMORY_IO" />
	<description>These events reflect request flow between units and nodes, as selected by the UnitMask. The UnitMask is divided into two fields: request type (CPU or IO access to IO or Memory) and source/target location (local vs. remote). One or more requests types must be enabled via bits 3:0, and at least one source and one target location must be selected via bits 7:4. Each event reflects a request of the selected type(s) going from the selected source(s) to the selected target(s). Note: It is not possible to tell from these events how much data is going in which direction, as there is no distinction between reads and writes. Also, particularly for IO, the requests may be for varying amounts of data, anywhere from one to sixty-four bytes.For a direct measure of the amount and direction of data flowing between nodes, use events F6h, F7h and F8h.</description>
</event>

<event name="Cache Block Commands" abbreviation="Cache block cmd" value="ea" >
	<mask value="0" name="Victim Block (Writeback)" />
	<mask value="2" name="Read Block (Dcache load miss refill)" />
	<mask value="3" name="Read Block Shared (Icache refill)" />
	<mask value="4" name="Read Block Modified (Dcache store miss refill)" />
	<mask value="5" name="Change-to-Dirty (first store to clean block already in cache)" />
	<op_name name="op" value="CACHE_BLOCK_COMMANDS" />
	<description>The number of requests made to the system for cache line transfers or coherency state changes, by request type. Each increment represents one cache line transfer, except for Change-to-Dirty. If a Change-to-Dirty request hits on a line in another processor's cache that's in the Owned state, it causes a cache line transfer, otherwise there is no data transfer associated with Change-to-Dirty requests.</description>
</event>

<event name="Sized Commands" abbreviation="Sized cmd" value="eb" >
	<mask value="0" name="Non-Posted SzWr Byte (1-32 bytes)" />
	<mask value="1" name="Non-Posted SzWr DW (1-16 dwords)" />
	<mask value="2" name="Posted SzWr Byte (1-32 bytes)" />
	<mask value="3" name="Posted SzWr DW (1-16 dwords)" />
	<mask value="4" name="SzRd Byte (4 bytes)" />
	<mask value="5" name="SzRd DW (1-16 dwords)" />
	<op_name name="op" value="SIZED_COMMANDS" />
	<description>The number of Sized Read/Write commands handled by the System Request Interface (local processor and hostbridge interface to the system). These commands may originate from the processor or hostbridge. Typical uses of the various Sized Read/Write commands are given in the UnitMask table. See NBPMCx0EC, which provides a separate measure of Hostbridge accesses.</description>
</event>

<event name="Probe Responses and Upstream Requests" abbreviation="Probe resp/up req" value="ec" >
	<mask value="0" name="Probe miss" />
	<mask value="1" name="Probe hit clean" />
	<mask value="2" name="Probe hit dirty without memory cancel (probed by Sized Write or Change2Dirty)" />
	<mask value="3" name="Probe hit dirty with memory cancel (probed by DMA read/cache refill request)" />
	<mask value="4" name="Upstream display refresh/ISOC reads" />
	<mask value="5" name="Upstream non-display refresh reads" />
	<mask value="6" name="Upstream ISOC writes" />
	<mask value="7" name="Upstream non-ISOC writes" />
	<op_name name="op" value="PROBE_RESPONSES_AND_UPSTREAM_REQUESTS" />
	<description>This covers two unrelated sets of events: cache probe results, and requests received by the hostbridge from
devices on non-coherent links.
Probe results: These events reflect the results of probes sent from a memory controller to local caches. They provide an indication of the degree data and code is shared between processors (or moved between processors due to process migration). The dirty-hit events indicate the transfer of a 64-byte cache line to the requestor (for a read or cache refill) or the target memory (for a write). The system bandwidth used by these, in terms of bytes per unit of time, may be calculated as 64 times the event count, divided by the elapsed time. Sized writes to memory that cover a full cache line do not incur this cache line transfer -- they simply invalidate the line and are reported as clean hits. Cache line transfers occur for Change2Dirty requests that hit cache lines in the Owned state. (Such cache lines are counted as Modified-state refills for PMCx06C, System Read Responses.) Upstream requests: The upstream read and write events reflect requests originating from a device on a local IO link. The two read events allow display refresh traffic in a UMA system to be measured separately from other DMA activity. Display refresh traffic is typically dominated by 64-byte transfers. Non-display-related DMA accesses may be anywhere from 1 to 64 bytes in size, but may be dominated by a particular size such as 32 or 64 bytes, depending on the nature of the devices.</description>
</event>

<event name="GART Events" abbreviation="GART events" value="ee" >
	<mask value="0" name="GART aperture hit on access from CPU" />
	<mask value="1" name="GART aperture hit on access from IO" />
	<mask value="2" name="GART miss" />
	<mask value="3" name="GART Request hit table walk in progress" />
	<mask value="7" name="GART multiple table walk in progress" />
	<op_name name="op" value="GART_EVENTS" />
	<description>These events reflect GART activity, and in particular allow one to calculate the GART TLB miss ratio as GART_miss_count divided by GART_aperture_hit_count. GART aperture accesses are typically from IO devices as opposed to the processor, and generally from a 3D graphics accelerator, but can be from other devices when the GART is used as an IOMMU.</description>
</event>

<event name="HyperTransport(tm) Link 0 Transmit Bandwidth" abbreviation="HT0 bandwidth" value="f6" >
	<mask value="0" name="Command DW sent" />
	<mask value="1" name="Data DW sent" />
	<mask value="2" name="Buffer release DW sent" />
	<mask value="3" name="Nop DW sent (idle)" />
	<mask value="4" name="Address (including extensions) DW sent" />
	<mask value="5" name="Per packet CRC sent" />
	<mask value="7" name="SubLink Mask" />
	<op_name name="op" value="HYPERTRANSPORT_LINK0_TRANSMIT_BANDWIDTH" />
	<description>Register Mapping for NBPMCx[1F9,0F8,0F7,0F6]: Register=>Function: NBPMCx0F6=>Link 0, NBPMCx0F7=>Link 1, NBPMCx0F8=>Link 2, NBPMCx1F9=>Link 3. The number of DWs transmitted (or unused, in the case of NOPs) on the outgoing side of the links. The count for (UnitMask[7:0]==3Fh) is the maximum transmission rate of the link. Link utilization may be calculated by (The count for (UnitMask[7:0]==37h))/(The count for (UnitMask[7:0]==3Fh)), described as non-NOP traffic divided by total traffic. Bandwidth in terms of bytes per unit time for any one component or combination of components is calculated by multiplying the count by four and dividing by elapsed time. The Data event provides a direct indication of the flow of data around the system. Translating this link-based view into a source/target node based view requires knowledge of the system layout (i.e. which links connect to which nodes).</description>
</event>

<event name="HyperTransport(tm) Link 1 Transmit Bandwidth" abbreviation="HT1 bandwidth" value="f7" >
	<mask value="0" name="Command DW sent" />
	<mask value="1" name="Data DW sent" />
	<mask value="2" name="Buffer release DW sent" />
	<mask value="3" name="Nop DW sent (idle)" />
	<mask value="4" name="Address (including extensions) DW sent" />
	<mask value="5" name="Per packet CRC sent" />
	<mask value="7" name="SubLink Mask" />
	<op_name name="op" value="HYPERTRANSPORT_LINK1_TRANSMIT_BANDWIDTH" />
	<description>Register Mapping for NBPMCx[1F9,0F8,0F7,0F6]: Register=>Function: NBPMCx0F6=>Link 0, NBPMCx0F7=>Link 1, NBPMCx0F8=>Link 2, NBPMCx1F9=>Link 3. The number of DWs transmitted (or unused, in the case of NOPs) on the outgoing side of the links. The count for (UnitMask[7:0]==3Fh) is the maximum transmission rate of the link. Link utilization may be calculated by (The count for (UnitMask[7:0]==37h))/(The count for (UnitMask[7:0]==3Fh)), described as non-NOP traffic divided by total traffic. Bandwidth in terms of bytes per unit time for any one component or combination of components is calculated by multiplying the count by four and dividing by elapsed time. The Data event provides a direct indication of the flow of data around the system. Translating this link-based view into a source/target node based view requires knowledge of the system layout (i.e. which links connect to which nodes).</description>
</event>

<event name="HyperTransport(tm) Link 2 Transmit Bandwidth" abbreviation="HT2 bandwidth" value="f8" >
	<mask value="0" name="Command DW sent" />
	<mask value="1" name="Data DW sent" />
	<mask value="2" name="Buffer release DW sent" />
	<mask value="3" name="Nop DW sent (idle)" />
	<mask value="4" name="Address (including extensions) DW sent" />
	<mask value="5" name="Per packet CRC sent" />
	<mask value="7" name="SubLink Mask" />
	<op_name name="op" value="HYPERTRANSPORT_LINK2_TRANSMIT_BANDWIDTH" />
	<description>Register Mapping for NBPMCx[1F9,0F8,0F7,0F6]: Register=>Function: NBPMCx0F6=>Link 0, NBPMCx0F7=>Link 1, NBPMCx0F8=>Link 2, NBPMCx1F9=>Link 3. The number of DWs transmitted (or unused, in the case of NOPs) on the outgoing side of the links. The count for (UnitMask[7:0]==3Fh) is the maximum transmission rate of the link. Link utilization may be calculated by (The count for (UnitMask[7:0]==37h))/(The count for (UnitMask[7:0]==3Fh)), described as non-NOP traffic divided by total traffic. Bandwidth in terms of bytes per unit time for any one component or combination of components is calculated by multiplying the count by four and dividing by elapsed time. The Data event provides a direct indication of the flow of data around the system. Translating this link-based view into a source/target node based view requires knowledge of the system layout (i.e. which links connect to which nodes).</description>
</event>

<event name="HyperTransport(tm) Link 3 Transmit Bandwidth" abbreviation="HT3 bandwidth" value="1f9" >
	<mask value="0" name="Command DW sent" />
	<mask value="1" name="Data DW sent" />
	<mask value="2" name="Buffer release DW sent" />
	<mask value="3" name="Nop DW sent (idle)" />
	<mask value="4" name="Address (including extensions) DW sent" />
	<mask value="5" name="Per packet CRC sent" />
	<mask value="7" name="SubLink Mask" />
	<op_name name="op" value="HYPERTRANSPORT_LINK3_TRANSMIT_BANDWIDTH" />
	<description>Register Mapping for NBPMCx[1F9,0F8,0F7,0F6]: Register=>Function: NBPMCx0F6=>Link 0, NBPMCx0F7=>Link 1, NBPMCx0F8=>Link 2, NBPMCx1F9=>Link 3. The number of DWs transmitted (or unused, in the case of NOPs) on the outgoing side of the links. The count for (UnitMask[7:0]==3Fh) is the maximum transmission rate of the link. Link utilization may be calculated by (The count for (UnitMask[7:0]==37h))/(The count for (UnitMask[7:0]==3Fh)), described as non-NOP traffic divided by total traffic. Bandwidth in terms of bytes per unit time for any one component or combination of components is calculated by multiplying the count by four and dividing by elapsed time. The Data event provides a direct indication of the flow of data around the system. Translating this link-based view into a source/target node based view requires knowledge of the system layout (i.e. which links connect to which nodes).</description>
</event>

<event name="CPU to DRAM Requests to Target Node" abbreviation="CPU to DRAM req to node" value="1e0" >
	<mask value="0" name="From Local node to Node 0" />
	<mask value="1" name="From Local node to Node 1" />
	<mask value="2" name="From Local node to Node 2" />
	<mask value="3" name="From Local node to Node 3" />
	<mask value="4" name="From Local node to Node 4" />
	<mask value="5" name="From Local node to Node 5" />
	<mask value="6" name="From Local node to Node 6" />
	<mask value="7" name="From Local node to Node 7" />
	<op_name name="op" value="CPU_DRAM_REQUEST_TO_NODE" />
	<description>This event counts all DRAM reads and writes generated by cores on the local node to the targeted node in the coherent fabric. This counter can be used to observe processor data affinity in NUMA aware operating systems.</description>
</event>

<event name="IO to DRAM Requests to Target Node" abbreviation="IO to DRAM req to node" value="1e1" >
	<mask value="0" name="From Local node to Node 0" />
	<mask value="1" name="From Local node to Node 1" />
	<mask value="2" name="From Local node to Node 2" />
	<mask value="3" name="From Local node to Node 3" />
	<mask value="4" name="From Local node to Node 4" />
	<mask value="5" name="From Local node to Node 5" />
	<mask value="6" name="From Local node to Node 6" />
	<mask value="7" name="From Local node to Node 7" />
	<op_name name="op" value="IO_DRAM_REQUEST_TO_NODE" />
	<description>This event counts all DRAM reads and writes generated by IO devices attached to the IO links of the local node the targeted node in the coherent fabric. This counter can be used to observe IO device data affinity in NUMA aware operating systems.</description>
</event>

<event name="CPU Read Command Latency to Target Node 0-3" abbreviation="CPU read cmd lat to node 0-3" value="1e2" >
	<mask value="0" name="Read block" />
	<mask value="1" name="Read block shared" />
	<mask value="2" name="Read block modified" />
	<mask value="3" name="Change-to-Dirty" />
	<mask value="4" name="From Local node to Node 0" />
	<mask value="5" name="From Local node to Node 1" />
	<mask value="6" name="From Local node to Node 2" />
	<mask value="7" name="From Local node to Node 3" />
	<op_name name="op" value="CPU_READ_COMMAND_LATENCY_NODE_0_3" />
	<description>This event counts the number of NB clocks from when the targeted command is received in the NB to when the targeted command completes. This event only tracks one outstanding command at a time. To determine latency between the local node and a remote node set UnitMask[7:4] to select the node and UnitMask[3:0] to select the read command type. The count returned by the counter should be divided by the count returned by NBPMCx1E3 do determine the average latency for the command type.</description>
</event>

<event name="CPU Read Command Requests to Target Node 0-3" abbreviation="CPU read cmd req to node 0-3" value="1e3" >
	<mask value="0" name="Read block" />
	<mask value="1" name="Read block shared" />
	<mask value="2" name="Read block modified" />
	<mask value="3" name="Change-to-Dirty" />
	<mask value="4" name="From Local node to Node 0" />
	<mask value="5" name="From Local node to Node 1" />
	<mask value="6" name="From Local node to Node 2" />
	<mask value="7" name="From Local node to Node 3" />
	<op_name name="op" value="CPU_READ_COMMAND_REQUEST_NODE_0_3" />
	<description>This event counts the number of requests that a latency measurement is made for using NBPMCx1E2. To determine the number of commands that a latency measurement are made for between the local node and a remote node set UnitMask[7:4] to select the node and UnitMask[3:0] to select the read command type.</description>
</event>

<event name="CPU Read Command Latency to Target Node 4-7" abbreviation="CPU read cmd lat to node 4-7" value="1e4" >
	<mask value="0" name="Read block" />
	<mask value="1" name="Read block shared" />
	<mask value="2" name="Read block modified" />
	<mask value="3" name="Change-to-Dirty" />
	<mask value="4" name="From Local node to Node 4" />
	<mask value="5" name="From Local node to Node 5" />
	<mask value="6" name="From Local node to Node 6" />
	<mask value="7" name="From Local node to Node 7" />
	<op_name name="op" value="CPU_READ_COMMAND_LATENCY_NODE_4_7" />
	<description>This event counts the number of NB clocks from when the targeted command is received in the NB to when the targeted command completes. This event only tracks one outstanding command at a time. To determine latency between the local node and a remote node set UnitMask[7:4] to select the node and UnitMask[3:0] to select the read command type. The count returned by the counter should be divided by the count returned by NBPMCx1E5 do determine the average latency for the command type.</description>
</event>

<event name="CPU Read Command Requests to Target Node 4-7" abbreviation="CPU read cmd req to node 4-7" value="1e5" >
	<mask value="0" name="Read block" />
	<mask value="1" name="Read block shared" />
	<mask value="2" name="Read block modified" />
	<mask value="3" name="Change-to-Dirty" />
	<mask value="4" name="From Local node to Node 4" />
	<mask value="5" name="From Local node to Node 5" />
	<mask value="6" name="From Local node to Node 6" />
	<mask value="7" name="From Local node to Node 7" />
	<op_name name="op" value="CPU_READ_COMMAND_REQUEST_NODE_4_7" />
	<description>This event counts the number of requests that a latency measurement is made for using NBPMCx1E4. To determine the number of commands that a latency measurement are made for between the local node and a remote node set UnitMask[7:4] to select the node and UnitMask[3:0] to select the read command type.</description>
</event>

<event name="CPU Command Latency to Target Node 0-3/4-7" abbreviation="CPU cmd lat to node 0-3/4-7" value="1e6" >
	<mask value="0" name="Read Sized" />
	<mask value="1" name="Write Sized" />
	<mask value="2" name="Victim Block" />
	<mask value="3" name="Node Group Select: 0=Nodes 0-3, 1= Nodes 4-7" />
	<mask value="4" name="From Local node to Node 0/4" />
	<mask value="5" name="From Local node to Node 1/5" />
	<mask value="6" name="From Local node to Node 2/6" />
	<mask value="7" name="From Local node to Node 3/7" />
	<op_name name="op" value="CPU_COMMAND_LATENCY_TARGET" />
	<description>This event counts the number of NB clocks from when the targeted command is received in the NB to when the targeted command completes. This event only tracks one outstanding command at a time. To determine latency between the local node and a remote node set UnitMask[7:4] to select the node, UnitMask[3] to select the node group and UnitMask[3:0] to select the command type. The count returned by the counter should be divided by the count returned by NBPMCx1E7 do determine the average latency for the command type.</description>
</event>

<event name="CPU Requests to Target Node 0-3/4-7" abbreviation="CPU req to node 0-3/4-7" value="1e7" >
	<mask value="0" name="Read Sized" />
	<mask value="1" name="Write Sized" />
	<mask value="2" name="Victim Block" />
	<mask value="3" name="Node Group Select: 0=Nodes 0-3, 1= Nodes 4-7" />
	<mask value="4" name="From Local node to Node 0/4" />
	<mask value="5" name="From Local node to Node 1/5" />
	<mask value="6" name="From Local node to Node 2/6" />
	<mask value="7" name="From Local node to Node 3/7" />
	<op_name name="op" value="CPU_REQUEST_TARGET" />
	<description>This event counts the number of requests that a latency measurement is made for using NBPMCx1E6. To determine the number of commands that a latency measurement are made for between the local node and a remote node set UnitMask[7:4] to select the node, UnitMask[3] to select the node group and UnitMask[3:0] to select the command type.</description>
</event>

<event name="Request Cache Status 0" abbreviation="Req cache status 0" value="1ea" >
	<mask value="0" name="Probe Hit S" />
	<mask value="1" name="Probe Hit E" />
	<mask value="2" name="Probe Hit MuW or O" />
	<mask value="3" name="Probe Hit M" />
	<mask value="4" name="Probe Miss" />
	<mask value="5" name="Directed Probe" />
	<mask value="6" name="Track Cache Stat for RdBlk" />
	<mask value="7" name="Track Cache Stat for RdBlkS" />
	<op_name name="op" value="REQUEST_CACHE_STATUS_0" />
	<description>The probe response type for RdBlk or RdBlkS request type.</description>
</event>

<event name="Request Cache Status 1" abbreviation="Req cache status 1" value="1eb" >
	<mask value="0" name="Probe Hit S" />
	<mask value="1" name="Probe Hit E" />
	<mask value="2" name="Probe Hit MuW or O" />
	<mask value="3" name="Probe Hit M" />
	<mask value="4" name="Probe Miss" />
	<mask value="5" name="Directed Probe" />
	<mask value="6" name="Track Cache Stat for ChgToDirty" />
	<mask value="7" name="Track Cache Stat for RdBlkM" />
	<op_name name="op" value="REQUEST_CACHE_STATUS_1" />
	<description>The probe response type for RdBlkM or ChgToDirty request type.</description>
</event>

<event name="Memory Controller Requests" abbreviation="MCT Requests" value="1f0" >
	<mask value="0" name="Write requests sent to the DCT" />
	<mask value="1" name="Read requests (including prefetch requests) sent to the DCT" />
	<mask value="2" name="Prefetch requests sent to the DCT" />
	<mask value="3" name="32 Bytes Sized Writes" />
	<mask value="4" name="64 Bytes Sized Writes" />
	<mask value="5" name="32 Bytes Sized Reads" />
	<mask value="6" name="64 Byte Sized Reads" />
	<mask value="7" name="Read requests sent to the DCT while writes requests are pending in the DCT" />
	<op_name name="op" value="MEMORY_CONTROLLER_REQUESTS" />
	<description>Read/Write requests: The read/write request events reflect the total number of commands sent to the DRAM controller. Sized Read/Write activity: The Sized Read/Write events reflect 32- or 64-byte transfers (as opposed to other sizes which could be anywhere between 1 and 64 bytes), from either the processor or the Hostbridge (on any node in an MP system). Such accesses from the processor would be due only to write combining buffer flushes, where 32-byte accesses would reflect flushes of partially-filled buffers. PMCx065 provides a count of sized write requests associated with WC buffer flushes; comparing that with counts for these events (providing there is very little Hostbridge activity at the same time) gives an indication of how efficiently the write combining buffers are being used. PMCx065 may also be useful in factoring out WC flushes when comparing these events with the Upstream Requests component of PMCx06C.</description>
</event>

<event name="Read Request to L3 Cache" abbreviation="Read req L3" value="4e0" >
	<mask value="0" name="Read Block Exclusive (Data cache read)" />
	<mask value="1" name="Read Block Shared (Instruction cache read)" />
	<mask value="2" name="Read Block Modify" />
	<mask value="3" name="1=Count prefetch only, 0=Count prefetch and non-prefetch" />
	<mask value="4" name="CoreSel: Logical core select, bit 0" />
	<mask value="5" name="CoreSel: Logical core select, bit 1" />
	<mask value="6" name="CoreSel: Logical core select, bit 2" />
	<mask value="7" name="CoreSel: Logical core select, bit 3" />
	<op_name name="op" value="READ_REQUEST_L3_CACHE" />
	<description>This event counts the read requests from each core to the L3 cache including canceled requests.</description>
</event>

<event name="L3 Cache Misses" abbreviation="L3 misses" value="4e1" >
	<mask value="0" name="Read Block Exclusive (Data cache read)" />
	<mask value="1" name="Read Block Shared (Instruction cache read)" />
	<mask value="2" name="Read Block Modify" />
	<mask value="3" name="1=Count prefetch only, 0=Count prefetch and non-prefetch" />
	<mask value="4" name="CoreSel: Logical core select, bit 0" />
	<mask value="5" name="CoreSel: Logical core select, bit 1" />
	<mask value="6" name="CoreSel: Logical core select, bit 2" />
	<mask value="7" name="CoreSel: Logical core select, bit 3" />
	<op_name name="op" value="L3_CACHE_MISSES" />
	<description>This event counts the number of L3 cache misses for accesses from each core. The approximate number of L3 hits can be determined by subtracting this event from NBPMCx4E0.</description>
</event>

<event name="L3 Fills caused by L2 Evictions" abbreviation="L3 fills" value="4e2" >
	<mask value="0" name="Shared" />
	<mask value="1" name="Exclusive" />
	<mask value="2" name="Owned" />
	<mask value="3" name="Modified" />
	<mask value="4" name="CoreSel: Logical core select, bit 0" />
	<mask value="5" name="CoreSel: Logical core select, bit 1" />
	<mask value="6" name="CoreSel: Logical core select, bit 2" />
	<mask value="7" name="CoreSel: Logical core select, bit 3" />
	<op_name name="op" value="L3_FILLS_CAUSED_BY_L2_EVICTIONS" />
	<description>This event counts the number of L3 fills caused by L2 evictions.</description>
</event>

<event name="L3 Evictions" abbreviation="L3 evictions" value="4e3" >
	<mask value="0" name="Shared" />
	<mask value="1" name="Exclusive" />
	<mask value="2" name="Owned" />
	<mask value="3" name="Modified" />
	<op_name name="op" value="L3_EVICTIONS" />
	<description>This event counts the state of the L3 lines when they are evicted from the L3 cache.</description>
</event>

<event name="Non-canceled L3 Read Requests" abbreviation="Non-can L3 read req" value="4ed" >
	<mask value="0" name="RdBlk" />
	<mask value="1" name="RdBlkS" />
	<mask value="2" name="RdBlkM" />
	<mask value="3" name="1=Count prefetch only; 0=Count prefetch and non-prefetch" />
	<mask value="4" name="CoreSel: Logical core select, bit 0" />
	<mask value="5" name="CoreSel: Logical core select, bit 1" />
	<mask value="6" name="CoreSel: Logical core select, bit 2" />
	<mask value="7" name="CoreSel: Logical core select, bit 3" />
	<op_name name="op" value="NON_CANCELLED_L3_READ_REQUESTS" />
	<description>This event tracks all read requests from each core to the L3 cache that are not canceled.</description>
</event>

<event name="L3 Latency" abbreviation="L3 latency" value="4ef" >
	<mask value="0" name="L3CycCount. L3 Request cycle count" />
	<mask value="1" name="L3ReqCount. L3 request count" />
	<op_name name="op" value="L3_LATENCY" />
	<description>This event enables the average latency for L3 requests to be calculated (L3CycCount/L3ReqCount).</description>
</event>

</source>

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
; EX
;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;

<source unit="EX">

<event name="All IBS fetch samples" abbreviation="IBS fetch" value="f000" >
	<op_name name="op" value="IBS_FETCH_ALL" />
	<description>The number of all IBS fetch samples. This derived event counts the number of all IBS fetch samples that were collected including IBS-killed fetch samples.</description>
</event>

<event name="IBS fetch killed" abbreviation="IBS fetch killed" value="f001" >
	<op_name name="op" value="IBS_FETCH_KILLED" />
	<description>The number of IBS sampled fetches that were killed fetches. A fetch operation is killed if the fetch did not reach ITLB or IC access. The number of killed fetch samples is not generally useful for analysis and are filtered out in other derived IBS fetch events (except Event Select 0xF000 which counts all IBS fetch samples including IBS killed fetch samples.)</description>
</event>

<event name="IBS fetch attempted" abbreviation="IBS fetch attempt" value="f002" >
	<op_name name="op" value="IBS_FETCH_ATTEMPTED" />
	<description>The number of IBS sampled fetches that were not killed fetch attempts. This derived event measures the number of useful fetch attempts and does not include the number of IBS killed fetch samples. This event should be used to compute ratios such as the ratio of IBS fetch IC misses to attempted fetches. The number of attempted fetches should equal the sum of the number of completed fetches and the number of aborted fetches.</description>
</event>

<event name="IBS fetch completed" abbreviation="IBS fetch comp" value="f003" >
	<op_name name="op" value="IBS_FETCH_COMPLETED" />
	<description>The number of IBS sampled fetches that completed. A fetch is completed if the attempted fetch delivers instruction data to the instruction decoder. Although the instruction data was delivered, it may still not be used (e.g., the instruction data may have been on the "wrong path" of an incorrectly predicted branch.)</description>
</event>

<event name="IBS fetch aborted" abbreviation="IBS fetch abort" value="f004" >
	<op_name name="op" value="IBS_FETCH_ABORTED" />
	<description>The number of IBS sampled fetches that aborted. An attempted fetch is aborted if it did not complete and deliver instruction data to the decoder. An attempted fetch may abort at any point in the process of fetching instruction data. An abort may be due to a branch redirection as the result of a mispredicted branch. The number of IBS aborted fetch samples is a lower bound on the amount of unsuccessful, speculative fetch activity. It is a lower bound since the instruction data delivered by completed fetches may not be used.</description>
</event>

<event name="IBS ITLB hit" abbreviation="IBS L1 ITLB hit" value="f005" >
	<op_name name="op" value="IBS_FETCH_ITLB_HITS" />
	<description>The number of IBS attempted fetch samples where the fetch operation initially hit in the L1 ITLB (Instruction Translation Lookaside Buffer).</description>
</event>

<event name="IBS L1 ITLB misses (and L2 ITLB hits)" abbreviation="IBS ITLB L1M L2H" value="f006" >
	<op_name name="op" value="IBS_FETCH_L1_ITLB_MISSES_L2_ITLB_HITS" />
	<description>The number of IBS attempted fetch samples where the fetch operation initially missed in the L1 ITLB and hit in the L2 ITLB.</description>
</event>

<event name="IBS L1 L2 ITLB miss" abbreviation="IBS ITLB L1M L2M" value="f007" >
	<op_name name="op" value="IBS_FETCH_L1_ITLB_MISSES_L2_ITLB_MISSES" />
	<description>The number of IBS attempted fetch samples where the fetch operation initially missed in both the L1 ITLB and the L2 ITLB.</description>
</event>

<event name="IBS instruction cache misses" abbreviation="IBS IC miss" value="f008" >
	<op_name name="op" value="IBS_FETCH_ICACHE_MISSES" />
	<description>The number of IBS attempted fetch samples where the fetch operation initially missed in the IC (instruction cache).</description>
</event>

<event name="IBS instruction cache hit" abbreviation="IBS IC hit" value="f009" >
	<op_name name="op" value="IBS_FETCH_ICACHE_HITS" />
	<description>The number of IBS attempted fetch samples where the fetch operation initially hit in the IC.</description>
</event>

<event name="IBS 4K page translation" abbreviation="IBS 4K page" value="f00a" >
	<op_name name="op" value="IBS_FETCH_4K_PAGE" />
	<description>The number of IBS attempted fetch samples where the fetch operation produced a valid physical address (i.e., address translation completed successfully) and used a 4-KByte page entry in the L1 ITLB.</description>
</event>

<event name="IBS 2M page translation" abbreviation="IBS 2M page" value="f00b" >
	<op_name name="op" value="IBS_FETCH_2M_PAGE" />
	<description>The number of IBS attempted fetch samples where the fetch operation produced a valid physical address (i.e., address translation completed successfully) and used a 2-MByte page entry in the L1 ITLB.</description>
</event>

<event name="IBS fetch latency" abbreviation="IBS fetch lat" value="f00e" >
	<op_name name="op" value="IBS_FETCH_LATENCY" />
	<description>The total latency of all IBS attempted fetch samples. Divide the total IBS fetch latency by the number of IBS attempted fetch samples to obtain the average latency of the attempted fetches that were sampled.</description>
</event>

<event name="All IBS op samples" abbreviation="IBS all ops" value="f100" >
	<op_name name="op" value="IBS_OP_ALL" />
	<description>The number of all IBS op samples that were collected. These op samples may be branch ops, resync ops, ops that perform load/store operations, or undifferentiated ops (e.g., those ops that perform arithmetic operations, logical operations, etc.). IBS collects data for retired ops. No data is collected for ops that are aborted due to pipeline flushes, etc. Thus, all sampled ops are architecturally significant and contribute to the successful forward progress of executing programs.</description>
</event>

<event name="IBS tag-to-retire cycles" abbreviation="IBS tag-to-ret" value="f101" >
	<op_name name="op" value="IBS_OP_TAG_TO_RETIRE" />
	<description>The total number of tag-to-retire cycles across all IBS op samples. The tag-to-retire time of an op is the number of cycles from when the op was tagged (selected for sampling) to when the op retired.</description>
</event>

<event name="IBS completion-to-retire cycles" abbreviation="IBS comp-to-ret" value="f102" >
	<op_name name="op" value="IBS_OP_COMP_TO_RET" />
	<description>The total number of completion-to-retire cycles across all IBS op samples. The completion-to-retire time of an op is the number of cycles from when the op completed to when the op retired.</description>
</event>

<event name="IBS branch op" abbreviation="IBS BR" value="f103" >
	<op_name name="op" value="IBS_OP_BRANCH_RETIRED" />
	<description>The number of IBS retired branch op samples. A branch operation is a change in program control flow and includes unconditional and conditional branches, subroutine calls and subroutine returns. Branch ops are used to implement AMD64 branch semantics.</description>
</event>

<event name="IBS mispredicted branch op" abbreviation="IBS misp BR" value="f104" >
	<op_name name="op" value="IBS_OP_MISPREDICTED_BRANCH" />
	<description>The number of IBS samples for retired branch operations that were mispredicted. This event should be used to compute the ratio of mispredicted branch operations to all branch operations.</description>
</event>

<event name="IBS taken branch op" abbreviation="IBS taken BR" value="f105" >
	<op_name name="op" value="IBS_OP_TAKEN_BRANCH" />
	<description>The number of IBS samples for retired branch operations that were taken branches.</description>
</event>

<event name="IBS mispredicted taken branch op" abbreviation="IBS misp taken BR" value="f106" >
	<op_name name="op" value="IBS_OP_MISPREDICTED_BRANCH_TAKEN" />
	<description>The number of IBS samples for retired branch operations that were mispredicted taken branches.</description>
</event>

<event name="IBS return op" abbreviation="IBS RET" value="f107" >
	<op_name name="op" value="IBS_OP_RETURNS" />
	<description>The number of IBS retired branch op samples where the operation was a subroutine return. These samples are a subset of all IBS retired branch op samples.</description>
</event>

<event name="IBS mispredicted return op" abbreviation="IBS misp RET" value="f108" >
	<op_name name="op" value="IBS_OP_MISPREDICTED_RETURNS" />
	<description>The number of IBS retired branch op samples where the operation was a mispredicted subroutine return. This event should be used to compute the ratio of mispredicted returns to all subroutine returns.</description>
</event>

<event name="IBS resync op" abbreviation="IBS resync" value="f109" >
	<op_name name="op" value="IBS_OP_RESYNC" />
	<description>The number of IBS resync op samples. A resync op is only found in certain microcoded AMD64 instructions and causes a complete pipeline flush.</description>
</event>

<event name="IBS all load store ops" abbreviation="IBS load/store" value="f200" >
	<op_name name="op" value="IBS_OP_ALL_LOAD_STORE" />
	<description>The number of IBS op samples for ops that perform either a load and/or store operation. An AMD64 instruction may be translated into one ("single fastpath"), two ("double fastpath"), or several ("vector path") ops. Each op may perform a load operation, a store operation or both a load and store operation (each to the same address). Some op samples attributed to an AMD64 instruction may perform a load/store operation while other op samples attributed to the same instruction may not. Further, some branch instructions perform load/store operations. Thus, a mix of op sample types may be attributed to a single AMD64 instruction depending upon the ops that are issued from the AMD64 instruction and the op types.</description>
</event>

<event name="IBS load ops" abbreviation="IBS load" value="f201" >
	<op_name name="op" value="IBS_OP_LOAD" />
	<description>The number of IBS op samples for ops that perform a load operation.</description>
</event>

<event name="IBS store ops" abbreviation="IBS store" value="f202" >
	<op_name name="op" value="IBS_OP_STORE" />
	<description>The number of IBS op samples for ops that perform a store operation.</description>
</event>

<event name="IBS L1 DTLB hit" abbreviation="IBS L1 DTLB hit" value="f203" >
	<op_name name="op" value="IBS_OP_L1_DTLB_HITS" />
	<description>The number of IBS op samples where either a load or store operation initially hit in the L1 DTLB (data translation lookaside buffer).</description>
</event>

<event name="IBS L1 DTLB misses L2 hits" abbreviation="IBS DTLB L1M L2H" value="f204" >
	<op_name name="op" value="IBS_OP_L1_DTLB_MISS_L2_DTLB_HIT" />
	<description>The number of IBS op samples where either a load or store operation initially missed in the L1 DTLB and hit in the L2 DTLB.</description>
</event>

<event name="IBS L1 and L2 DTLB misses" abbreviation="IBS DTLB L1M L2M" value="f205" >
	<op_name name="op" value="IBS_OP_L1_L2_DTLB_MISS" />
	<description>The number of IBS op samples where either a load or store operation initially missed in both the L1 DTLB and the L2 DTLB.</description>
</event>

<event name="IBS data cache misses" abbreviation="IBS DC miss" value="f206" >
	<op_name name="op" value="IBS_OP_DATA_CACHE_MISS" />
	<description>The number of IBS op samples where either a load or store operation initially missed in the data cache (DC).</description>
</event>

<event name="IBS data cache hits" abbreviation="IBS DC hit" value="f207" >
	<op_name name="op" value="IBS_OP_DATA_HITS" />
	<description>The number of IBS op samples where either a load or store operation initially hit in the data cache (DC).</description>
</event>

<event name="IBS misaligned data access" abbreviation="IBS misalign acc" value="f208" >
	<op_name name="op" value="IBS_OP_MISALIGNED_DATA_ACC" />
	<description>The number of IBS op samples where either a load or store operation caused a misaligned access (i.e., the load or store operation crossed a 128-bit boundary).</description>
</event>

<event name="IBS bank conflict on load op" abbreviation="IBS bank conf load" value="f209" >
	<op_name name="op" value="IBS_OP_BANK_CONF_LOAD" />
	<description>The number of IBS op samples where either a load or store operation caused a bank conflict with a load operation.</description>
</event>

<event name="IBS bank conflict on store op" abbreviation="IBS bank conf store" value="f20a" >
	<op_name name="op" value="IBS_OP_BANK_CONF_STORE" />
	<description>The number of IBS op samples where either a load or store operation caused a bank conflict with a store operation.</description>
</event>

<event name="IBS store-to-load forwarded" abbreviation="IBS forwarded" value="f20b" >
	<op_name name="op" value="IBS_OP_FORWARD" />
	<description>The number of IBS op samples where data for a load operation was forwarded from a store operation.</description>
</event>

<event name="IBS store-to-load cancelled" abbreviation="IBS STLF cancelled" value="f20c" >
	<op_name name="op" value="IBS_OP_CANCELLED" />
	<description>The number of IBS op samples where data forwarding to a load operation from a store was cancelled.</description>
</event>

<event name="IBS UC memory access" abbreviation="IBS UC mem acc" value="f20d" >
	<op_name name="op" value="IBS_OP_DCUC_MEM_ACC" />
	<description>The number of IBS op samples where a load or store operation accessed uncacheable (UC) memory.</description>
</event>

<event name="IBS WC memory access" abbreviation="IBS WC mem acc" value="f20e" >
	<op_name name="op" value="IBS_OP_DCWC_MEM_ACC" />
	<description>The number of IBS op samples where a load or store operation accessed write combining (WC) memory.</description>
</event>

<event name="IBS locked operation" abbreviation="IBS locked op" value="f20f" >
	<op_name name="op" value="IBS_OP_LOCKED" />
	<description>The number of IBS op samples where a load or store operation was a locked operation.</description>
</event>

<event name="IBS MAB hit" abbreviation="IBS MAB hit" value="f210" >
	<op_name name="op" value="IBS_OP_MAB_HIT" />
	<description>The number of IBS op samples where a load or store operation hit an already allocated entry in the Miss Address Buffer (MAB).</description>
</event>

<event name="IBS L1 DTLB 4K page" abbreviation="IBS L1 DTLB 4K" value="f211" >
	<op_name name="op" value="IBS_OP_L1_DTLB_4K" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address and a 4-KByte page entry in the L1 DTLB was used for address translation.</description>
</event>

<event name="IBS L1 DTLB 2M page" abbreviation="IBS L1 DTLB 2M" value="f212" >
	<op_name name="op" value="IBS_OP_L1_DTLB_2M" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address and a 2-MByte page entry in the L1 DTLB was used for address translation.</description>
</event>

<event name="IBS L1 DTLB 1G page" abbreviation="IBS L1 DTLB 1G" value="f213" >
	<op_name name="op" value="IBS_OP_L1_DTLB_1G" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address and a 1-GByte page entry in the L1 DTLB was used for address translation.</description>
</event>

<event name="IBS L2 DTLB 4K page" abbreviation="IBS L2 DTLB 4K" value="f215" >
	<op_name name="op" value="IBS_OP_L2_DTLB_4K" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address, hit the L2 DTLB, and used a 4 KByte page entry for address translation.</description>
</event>

<event name="IBS L2 DTLB 2M page" abbreviation="IBS L2 DTLB 2M" value="f216" >
	<op_name name="op" value="IBS_OP_L2_DTLB_2M" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address, hit the L2 DTLB, and used a 2-MByte page entry for address translation.</description>
</event>

<event name="IBS L2 DTLB 1G page" abbreviation="IBS L2 DTLB 1G" value="f217" >
	<op_name name="op" value="IBS_OP_L2_DTLB_1G" />
	<description>The number of IBS op samples where a load or store operation produced a valid linear (virtual) address, hit the L2 DTLB, and used a 1-GByte page entry for address translation.</description>
</event>

<event name="IBS data cache miss load latency" abbreviation="IBS DC miss lat" value="f219" >
	<op_name name="op" value="IBS_OP_DC_LOAD_LAT" />
	<description>The total DC miss load latency (in processor cycles) across all IBS op samples that performed a load operation and missed in the data cache. The miss latency is the number of clock cycles from when the data cache miss was detected to when data was delivered to the core. Divide the total DC miss load latency by the number of data cache misses to obtain the average DC miss load latency.</description>
</event>

<event name="IBS Northbridge local" abbreviation="IBS NB local" value="f240" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_ONLY" />
	<description>The number of IBS op samples where a load operation was serviced from the local processor. Northbridge IBS data is only valid for load operations that miss in both the L1 data cache and the L2 data cache. If a load operation crosses a cache line boundary, then the IBS data reflects the access to the lower cache line.</description>
</event>

<event name="IBS Northbridge remote" abbreviation="IBS NB remote" value="f241" >
	<op_name name="op" value="IBS_OP_NB_REMOTE_ONLY" />
	<description>The number of IBS op samples where a load operation was serviced from a remote processor.</description>
</event>

<event name="IBS Northbridge local L3" abbreviation="IBS NB local L3" value="f242" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_L3" />
	<description>The number of IBS op samples where a load operation was serviced by the local L3 cache.</description>
</event>

<event name="IBS Northbridge local core L1 or L2 cache" abbreviation="IBS NB local cache" value="f243" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_CACHE" />
	<description>The number of IBS op samples where a load operation was serviced by a cache (L1 data cache or L2 cache) belonging to a local core which is a sibling of the core making the memory request.</description>
</event>

<event name="IBS Northbridge local core L1, L2, L3 cache" abbreviation="IBS NB remote cache" value="f244" >
	<op_name name="op" value="IBS_OP_NB_REMOTE_CACHE" />
	<description>The number of IBS op samples where a load operation was serviced by a remote L1 data cache, L2 cache or L3 cache after traversing one or more coherent HyperTransport links.</description>
</event>

<event name="IBS Northbridge local DRAM" abbreviation="IBS NB local DRAM" value="f245" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_DRAM" />
	<description>The number of IBS op samples where a load operation was serviced by local system memory (local DRAM via the memory controller).</description>
</event>

<event name="IBS Northbridge remote DRAM" abbreviation="IBS NB remote DRAM" value="f246" >
	<op_name name="op" value="IBS_OP_NB_REMOTE_DRAM" />
	<description>The number of IBS op samples where a load operation was serviced by remote system memory (after traversing one or more coherent HyperTransport links and through a remote memory controller).</description>
</event>

<event name="IBS Northbridge local APIC MMIO Config PCI" abbreviation="IBS NB local other" value="f247" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_OTHER" />
	<description>The number of IBS op samples where a load operation was serviced from local MMIO, configuration or PCI space, or from the local APIC.</description>
</event>

<event name="IBS Northbridge remote APIC MMIO Config PCI" abbreviation="IBS NB remote other" value="f248" >
	<op_name name="op" value="IBS_OP_NB_REMOTE_OTHER" />
	<description>The number of IBS op samples where a load operation was serviced from remote MMIO, configuration or PCI space.</description>
</event>

<event name="IBS Northbridge cache modified state" abbreviation="IBS NB cache Modified" value="f249" >
	<op_name name="op" value="IBS_OP_NB_CACHE_MODIFIED" />
	<description>The number of IBS op samples where a load operation was serviced from local or remote cache, and the cache hit state was the Modified (M) state.</description>
</event>

<event name="IBS Northbridge cache owned state" abbreviation="IBS NB cache Owned" value="f24a" >
	<op_name name="op" value="IBS_OP_NB_CACHE_OWNED" />
	<description>The number of IBS op samples where a load operation was serviced from local or remote cache, and the cache hit state was the Owned (O) state.</description>
</event>

<event name="IBS Northbridge local cache latency" abbreviation="IBS NB local lat" value="f24b" >
	<op_name name="op" value="IBS_OP_NB_LOCAL_CACHE_LAT" />
	<description>The total data cache miss latency (in processor cycles) for load operations that were serviced by the local processor.</description>
</event>

<event name="IBS Northbridge remote cache latency" abbreviation="IBS NB remote lat" value="f24c" >
	<op_name name="op" value="IBS_OP_NB_REMOTE_CACHE_LAT" />
	<description>The total data cache miss latency (in processor cycles) for load operations that were serviced by a remote processor.</description>
</event>

<event name="Cache Line Utilization Percentage" abbreviation="Cache Line Utilization" value="ff00" >
	<op_name name="op" value="PERCENTAGE_CACHE_LINE_UTILIZATION" />
</event>

<event name="Line Boundary Crossings" abbreviation="Line Boundary Crossings" value="ff01" >
	<op_name name="op" value="LINE_BOUNDARY_CROSSINGS" />
</event>

<event name="Bytes/L1 Eviction" abbreviation="Bytes/L1 Eviction" value="ff02" >
	<op_name name="op" value="BYTES_PER_L1_EVICTION" />
</event>

<event name="Accesses/L1 Eviction" abbreviation="Accesses/L1 Eviction" value="ff03" >
	<op_name name="op" value="ACCESSES_PER_L1_EVICTION" />
</event>

<event name="L1 Evictions" abbreviation="L1 Evictions" value="ff04" >
	<op_name name="op" value="L1_EVICTION_COUNT" />
</event>

<event name="Accesses" abbreviation="Accesses" value="ff05" >
	<op_name name="op" value="L1_ACCESS_COUNT" />
</event>

<event name="Bytes Accessed" abbreviation="Bytes Accessed" value="ff06" >
	<op_name name="op" value="L1_BYTE_ACCESSED_COUNT" />
</event>

</source>

</cpu_events>
